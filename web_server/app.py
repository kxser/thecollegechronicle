#!/usr/bin/env python3
"""
Web Server version of the auto_article.py script
Provides a web interface for creating articles using AI assistance
"""

import os
import json
import re
import asyncio
import time
from datetime import datetime
from pathlib import Path
from typing import List, Optional, Dict, Any
import uvicorn
from fastapi import FastAPI, HTTPException, Form, Request
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel
import google.generativeai as genai
from dotenv import load_dotenv
import config

# Load environment variables
load_dotenv()

# Configuration  
BATCH_SIZE = 1  # Process one article at a time
SEPARATOR_LINE = "********------********"
API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyACP5jqTxVsVY0dCRQFNNv7wZi2nSfBx7k")  # Use environment variable or fallback

# Base prompt (same as original script)
BASE_PROMPT = """You are a meticulous copy editor for this project. You receive an article's text plus metadata in natural language. Your job is to make only mechanical corrections and construct a complete Markdown (.md) file that matches this project's front-matter, formatting, and file naming conventions. You may receive multiple articles in a single request. Process each one independently and output the final Markdown file for each article in the order provided, separating each completed file with a single blank line.

You MUST output VALID YAML front matter with:

writers as a YAML array (with a leading dash per writer)

categories as a YAML array (with a leading dash per category) when present

tags as a YAML array (with a leading dash per tag) ALWAYS

alternates as a YAML array of objects, each object on its own indented lines:

hreflang: xx
href: https://...
Do NOT output inline YAML for these fields. Do NOT output JSON arrays. Do NOT omit the leading dashes for arrays.

You MUST wrap the front matter between --- lines, then add exactly one blank line, then the corrected body.

INPUTS

Input may be structured or unstructured prose. Expect human-language metadata like:

"the author is Jane Doe"

"written on Oct 26 25"

"title is …", "description: …"

"category is …"

"alternate link en: https://…"

Required: article_text (the article body)

Optional: title, description, date, author, categories, alternates

Tags are always generated by you (see TAGS POLICY).

Never assume you can read or scan the filesystem.

TITLE POLICY (modified)

If the input already provides a title (e.g. "title is …" or it appears in existing front matter), KEEP IT EXACTLY (only fix obvious typos/punctuation).

If the input does NOT provide a title, you MUST generate one.

Generated titles must be:

unique and specific to the text,

not too long (aim for ~4–10 words),

not too short or generic ("Article," "Report," "Update," "Summary," "Notes," etc. are forbidden),

reflective of the main topic or angle of the piece,

in Title Case (Capitalize Every Major Word),

safe for slugification (no emojis).

The generated title must be used:

in the front matter title: "<title text>", and

in the filepath slug.

ALLOWED CHANGES TO BODY

Correct misspelled words.

Fix punctuation (commas, periods, quotes, apostrophes, dashes, parentheses, ellipses; spacing around punctuation).

Normalize typographic errors (balance quotes/brackets; remove duplicates like "!!").

Adjust paragraphing:

unwrap hard line breaks

ensure exactly one blank line between paragraphs

EXCEPTION FOR POETRY-FORM TEXTS (see POETRY / VERSE DETECTION): if the text is identified as poetry/verse (poem, haiku, acrostic, line-structured lyric), do not unwrap lines, do not merge stanzas, and preserve existing line/stanza breaks exactly (only fix obvious typos/punctuation).

OUT OF SCOPE

Do not:

Rephrase or rewrite sentences.

Change style, tone, or meaning.

Add or remove text.

Invent metadata (except tags, description, and category if missing).

Add headings, lists, or commentary.

POETRY / VERSE DETECTION

Before doing paragraphing, you must infer whether the body is regular prose or a line-structured text.

Treat the input as poetry/verse (and therefore preserve line breaks and stanza structure) when any of these are true:

The user explicitly says it is a "poem", "verse", "haiku", "acrostic", "sonnet", or similar — even if the text was pasted as one long block without line breaks. In this case, do not invent or reconstruct line breaks; preserve the block as given and only apply mechanical fixes.

The body consists mostly of short lines (e.g., most lines under ~70 characters) with deliberate line breaks that are not caused by wrapping.

The body shows clear acrostic intent (e.g., first letters of consecutive lines form a word/name).

The body is haiku-like (3 lines, or 3-line stanzas, season/nature imagery, syllabic pattern).

The metadata mentions or implies a poem/haiku/acrostic (e.g., "this is an autumn haiku", "here's an acrostic for our town") even if the pasted text is a single paragraph.

If none of the above indicators are present, treat it as regular prose.

Special case for pasted-without-line-breaks poetry:

If metadata or wording tells you it should be a poem/haiku/acrostic but the pasted text has no line breaks, do not attempt to reflow it into stanzas or add breaks — we do not invent structure. Keep the exact line/block structure, just fix mechanics.

Still categorize it as a creative/aesthetic piece (likely art) if no other valid category is given.

Paragraphing behavior by type:

If prose: join lines broken mid-sentence; ensure exactly one blank line between paragraphs.

Keep existing paragraph order.

Preserve lists, code blocks, blockquotes, links, and emphasis as-is.

Ensure exactly one blank line between paragraphs.

If poetry/verse (detected per section above): do not join lines; do not normalize to single-blank-line paragraphs inside stanzas; only correct mechanical errors.

If mixed (e.g., prose intro + poem): paragraph the prose part normally, but preserve the line structure of the poem part.

CATEGORIES POLICY (fixed allow-list)

Allowed categories (case-insensitive): ["science", "research", "opinion", "technology", "news", "misc", "art"]

Rules:

Normalize to lowercase.

Keep valid ones in order; deduplicate.

If multiple valid, keep them all (for YAML); the first one defines the filename.

If no valid categories are provided, auto-assign one based on article content:

Science/tech topics → science or technology

Current events or social commentary → news

Personal or reflective writing → opinion

Creative or aesthetic topics (including poetry/verse, even pasted in one block) → art

Otherwise default to misc

If at least one valid category remains, output:
categories:

<category1>
<category2>

Never output categories: <value> on a single line.

DESCRIPTION POLICY

If description is missing, generate a concise, neutral 1–2 sentence summary (≤ 200 characters) of the article's subject.

Use plain declarative style, no hype.

Derived from the first paragraph or key topic.

Never use quotes or markdown formatting.

If the article is a poem/haiku/acrostic (even if pasted as one paragraph), describe it as such, e.g. "Short poem about autumn and transience." or "Acrostic poem dedicated to the city."

TAGS POLICY

Always generate 3–8 lowercase tags (replace any provided ones).

Short keywords or 1–3-word phrases from the article body.

Only letters, numbers, and hyphens.

No personal names, no dates, no generic words like "news".

No duplicates.

Always output in YAML array form:

tags:

tag-one

tag-two

tag-three

For poems/haikus/acrostics (even if pasted as one block), include one tag reflecting form or theme, e.g. "poem", "haiku", "acrostic", or "lyric-poetry" in addition to topic tags.

FRONT MATTER SPEC AND ORDER

You MUST use exactly this key order (and omit a key only when the rules say so):

title IN QUOTES

description

date (YYYY-MM-DD)

writers (YAML array)

categories (YAML array; include only if at least one valid category is present)

tags (YAML array; always present)

alternates (YAML array of objects with keys: hreflang, href)

Exactly like this:

title: "<title text>"
description: <description text>
date: <YYYY-MM-DD>
writers:

<Writer Name>

categories:

<category-one>
<category-two>

tags:

<tag-one>
<tag-two>

alternates:

hreflang: en
href: https://...

If categories are not present or no valid category is found, omit the categories block entirely, but keep the order of the remaining keys.

FRONT MATTER RULES

If the input includes existing YAML front matter:

Preserve all existing keys and their values and original order except:

Apply allowed spelling/punctuation fixes to title/description text.

Ensure writers includes the extracted author (add if missing; keep as a YAML array with dashes).

Replace tags with freshly generated tags (see TAGS POLICY) and output them as a YAML array.

Filter categories per CATEGORIES POLICY (drop disallowed ones; if none remain, remove categories).

Preserve alternates exactly as provided (no guessing), and always output them as:
alternates:

hreflang: xx
href: https://...

If no front matter is provided:

Create front matter using the key order above.

Title:

If provided, use it verbatim (with mechanical fixes only).

If NOT provided, generate a unique, specific, non-generic, 4–10 word title in Title Case that matches the article's main subject.

Description: if missing, generate per DESCRIPTION POLICY.

Date: use provided date; if not provided, use today's date in the user's local time (YYYY-MM-DD).

Writers: a YAML array containing the extracted author (single item if one). If no author is given, output:
writers:

Unknown

Categories: include only if at least one provided category is in the allow-list, otherwise generate one per CATEGORIES POLICY.

Tags: always present (generated).

Alternates: include only if provided; each item must have hreflang and href, and each item must be a YAML object on its own line with proper indentation.

NATURAL LANGUAGE METADATA EXTRACTION

Author: extract from phrases like "author is …", "by …", "written by …". Use the exact name string as given (no reformatting).

Date: accept formats like "Oct 26 25", "Oct26 25", "10/26/2025", "2025-10-26", "October 26th, 2025".

Normalize to YYYY-MM-DD.

Two-digit years map to 20YY (e.g., "25" -> 2025).

If day/month are ambiguous (e.g., 03/04/25), prefer the user's locale if specified; otherwise assume month/day/year.

If no date is provided, use today's date in the user's local time.

Title/Description/Categories/Alternates: extract only when explicitly stated (e.g., "title is …", "description: …", "category is technology", "alternate en: https://…"). Do not infer.

If alternates are given in natural language, normalize to:

alternates:

hreflang: <lang-code>
href: <url>

MARKDOWN AND OUTPUT FORMAT

Output must be valid UTF-8 Markdown with LF line endings.

Do not include an H1 in the body; the project uses the title from front matter.

For each article provided, return only the final Markdown file content in the exact order received:

filepath line

YAML front matter delimited by ---

a single blank line

the corrected body

Separate each completed file with a single blank line. No extra commentary, explanations, or code fences.

FILEPATH LINE

Before the front matter, output a single line:
// filepath: content/<filename>

Filename = <category>-<slugified-title>.md

category: the first valid category (or "misc" if none)

slugified-title: lowercase, words separated by hyphens, non-alphanumerics removed except hyphens

example: science-scientists-synthesize-gold-using-novel-chemical-process.md

For poetry/verse assigned to art, the filename should still follow this rule, e.g. art-autumn-haiku.md

If the title was generated by you, use the generated title for the slug.

FINAL TASKS

Read the article_text and extract any metadata from natural language input.

Detect whether the body is prose or poetry/verse (poem, haiku, acrostic, or similar), including the case where the user tells you it's a poem but the text is pasted as a single block with no line breaks, and apply the correct paragraphing/preservation rules.

Apply only the allowed spelling, punctuation, and paragraphing fixes to the body.

Construct or preserve YAML front matter according to the Front Matter Spec, Categories Policy, Tags Policy, Description Policy, Poetry detection rules, Natural Language Metadata Extraction rules, and the modified Title Policy (generate unique, catchy-but-not-hype titles when missing).

Generate the filename per OUTPUT FILE NAMING and include the // filepath: content/<filename> line.

For each article, output only the final .md file content (filepath line, front matter, blank line, corrected body). Separate successive files with a single blank line.

Do NOT output explanatory text, comments, or code fences. Only the raw Markdown files.

VALIDATION RULES (must pass)

writers must be a YAML array (with dashes), never a single inline string.

tags must be a YAML array (with dashes), never comma-separated on one line.

categories, if present, must be a YAML array (with dashes).

alternates, if present, must be a YAML array of YAML objects, each starting with a dash, each with hreflang and href on their own lines.

Front matter must begin with --- and end with ---.

There must be exactly one blank line between front matter and body.

DO NOT FORGET: THE CURRENT YEAR IS 2026, NOT 2025.
"""

# Data models
class ArticleInput(BaseModel):
    title: Optional[str] = None
    date: Optional[str] = None
    author: Optional[str] = None
    category: Optional[str] = None
    body: str
    description: Optional[str] = None
    alternates: Optional[List[Dict[str, str]]] = None

class BatchArticleInput(BaseModel):
    articles: List[ArticleInput]
    model_name: str = "gemini-2.5-pro"

class ArticleResponse(BaseModel):
    success: bool
    files_created: List[str] = []
    error_message: Optional[str] = None
    raw_response: Optional[str] = None

# Initialize FastAPI app
app = FastAPI(title="Article Generator Web Server", version="1.0.0")

# Setup templates and static files - use absolute path
current_dir = Path(__file__).parent
templates = Jinja2Templates(directory=str(current_dir / "templates"))

# Initialize Gemini AI
genai.configure(api_key=API_KEY)

# Date parsing utilities (from original script)
DATE_FORMATS = [
    "%Y-%m-%d",
    "%Y/%m/%d", 
    "%m/%d/%Y",
    "%m/%d/%y",
    "%b %d %Y",
    "%b %d, %Y",
    "%B %d %Y", 
    "%B %d, %Y",
    "%b %d %y",
    "%B %d %y",
    "%d %b %Y",
    "%d %b, %Y",
    "%d %B %Y",
    "%d %B, %Y",
]

def resolve_date(value: str) -> str:
    """Convert various date formats to YYYY-MM-DD"""
    if not value:
        return datetime.now().date().isoformat()
    
    normalized = value.replace(",", " ")
    normalized = " ".join(normalized.split())
    normalized = re.sub(r"^([A-Za-z]{3,9})(\d{1,2})(\s+\d{2,4})$", r"\1 \2\3", normalized, flags=re.IGNORECASE)
    
    for fmt in DATE_FORMATS:
        try:
            dt = datetime.strptime(normalized, fmt)
            year = dt.year if dt.year >= 100 else dt.year + 2000
            return dt.replace(year=year).date().isoformat()
        except ValueError:
            continue
    
    raise ValueError(f"Unrecognized date format: {value}")

def build_batch_prompt(articles: List[ArticleInput]) -> str:
    """Build prompt for processing articles (optimized for single article)"""
    sections = []
    for idx, article in enumerate(articles, 1):
        title_line = f"title: {article.title}" if article.title else "GENERATE TITLE BASED ON TEXT"
        
        # Build the article section
        section_lines = [
            f"ARTICLE {idx}:",
            f"date: {resolve_date(article.date or '')}",
            f"author: {article.author or 'Unknown Writer'}",
            title_line,
        ]
        
        if article.category:
            section_lines.append(f"category: {article.category}")
        
        if article.description:
            section_lines.append(f"description: {article.description}")
        
        if article.alternates:
            for alt in article.alternates:
                section_lines.append(f"alternate {alt.get('hreflang', 'en')}: {alt.get('href', '')}")
        
        section_lines.extend([
            "article_text:",
            article.body,
            f"END ARTICLE {idx}",
        ])
        
        sections.append("\n".join(section_lines))
    
    # Add explicit instruction for single vs multiple articles
    if len(articles) == 1:
        instruction = "Here is the single article to process. Output only ONE complete markdown file:"
    else:
        instruction = f"Here are the {len(articles)} articles to process. Process each one independently and output {len(articles)} separate markdown files, each with its own filepath line:"
    
    return f"{BASE_PROMPT}\n\n{instruction}\n\n" + "\n\n".join(sections)

def extract_text(response) -> str:
    """Extract text from Gemini response"""
    text = getattr(response, "text", None)
    if text:
        return text
    
    try:
        parts = []
        for cand in getattr(response, "candidates", []) or []:
            content = getattr(cand, "content", None)
            if not content:
                continue
            for part in getattr(content, "parts", []) or []:
                segment = getattr(part, "text", None) or (part.get("text") if isinstance(part, dict) else None)
                if segment:
                    parts.append(segment)
        if parts:
            return "".join(parts)
    except Exception:
        pass
    
    return str(response)

def parse_and_create_files(response_text: str, content_dir: Path = None) -> List[str]:
    """Parse AI response and create markdown files"""
    if content_dir is None:
        # Get the parent directory of the web_server folder, then go to content
        current_dir = Path(__file__).parent
        content_dir = current_dir.parent / "content"
        print(f"Debug: Using content directory: {content_dir.absolute()}")
    
    # Split by filepath markers - this is more reliable than separators
    parts = []
    current_part = ""
    lines = response_text.split('\n')
    
    for i, line in enumerate(lines):
        if line.startswith('// filepath: '):
            # If we have accumulated content, save it as a part
            if current_part.strip():
                parts.append(current_part.strip())
            # Start new part with the filepath line
            current_part = line + '\n'
        else:
            current_part += line + '\n'
    
    # Add the last part if it exists
    if current_part.strip():
        parts.append(current_part.strip())
    
    # If no parts found, treat as single file
    if not parts:
        parts = [response_text]
    
    print(f"Debug: Split response into {len(parts)} parts")
    
    created_files = []
    
    for part in parts:
        part = part.strip()
        if not part:
            continue
        
        # Look for filepath line
        lines = part.split('\n')
        filepath_line = None
        content_start = 0
        
        for i, line in enumerate(lines):
            if line.startswith('// filepath: '):
                filepath_line = line
                content_start = i + 1
                break
        
        if not filepath_line:
            print("Warning: No filepath found in response part, skipping")
            continue
        
        # Extract filename from filepath line
        filepath = filepath_line.replace('// filepath: ', '').strip()
        filename = os.path.basename(filepath)
        
        # Get content starting from after the filepath line
        content_lines = lines[content_start:]
        
        # Find the start of YAML front matter (---)
        yaml_start = -1
        for i, line in enumerate(content_lines):
            if line.strip() == '---':
                yaml_start = i
                break
        
        if yaml_start == -1:
            print(f"Warning: No YAML front matter found for {filename}, skipping")
            continue
        
        # Content should start from the YAML front matter
        file_content = '\n'.join(content_lines[yaml_start:])
        
        # Create the file in the content directory
        content_dir.mkdir(exist_ok=True)
        file_path = content_dir / filename
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(file_content)
            created_files.append(str(file_path))
        except Exception as e:
            print(f"Error creating {file_path}: {e}")
    
    return created_files

# Routes
@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    """Home page with the article creation form"""
    return templates.TemplateResponse("index.html", {"request": request})

@app.post("/api/process-articles", response_model=ArticleResponse)
async def process_articles(batch_input: BatchArticleInput):
    """Process articles using AI and create markdown files"""
    try:
        print(f"Debug: Received {len(batch_input.articles)} articles for processing")
        for i, article in enumerate(batch_input.articles):
            print(f"Debug: Article {i+1} - Title: {article.title}, Author: {article.author}, Body length: {len(article.body) if article.body else 0}")
        
        model = genai.GenerativeModel(batch_input.model_name)
        
        # Process articles one by one with delays
        all_created_files = []
        all_responses = []
        
        articles = batch_input.articles
        for i, article in enumerate(articles):
            print(f"Debug: Processing article {i+1} of {len(articles)}")
            
            # Create a single-article batch for consistent prompt format
            single_article_batch = [article]
            prompt_text = build_batch_prompt(single_article_batch)
            
            try:
                response = model.generate_content(prompt_text)
                response_text = extract_text(response).strip()
                print(f"Debug: Article {i+1} - AI response length: {len(response_text)}")
                print(f"Debug: Article {i+1} - AI response preview: {response_text[:200]}...")
                
                # Immediately parse and create file for this article
                created_files = parse_and_create_files(response_text)
                all_created_files.extend(created_files)
                all_responses.append(response_text)
                
                print(f"Debug: Article {i+1} - Created {len(created_files)} files")
                
                # Wait 1 minute before processing the next article (except for the last one)
                if i < len(articles) - 1:
                    print(f"Debug: Waiting 60 seconds before processing next article...")
                    await asyncio.sleep(60)
                
            except Exception as exc:
                return ArticleResponse(
                    success=False,
                    error_message=f"AI generation error on article {i+1}: {str(exc)}"
                )
        
        # Combine all responses for debugging purposes
        combined = f"\n{SEPARATOR_LINE}\n".join(all_responses)
        
        print(f"Debug: Total created {len(all_created_files)} files: {all_created_files}")
        
        return ArticleResponse(
            success=True,
            files_created=all_created_files,
            raw_response=combined
        )
        
    except Exception as e:
        return ArticleResponse(
            success=False,
            error_message=str(e)
        )

@app.get("/api/models")
async def get_available_models():
    """Get list of available Gemini models"""
    return {
        "models": [model["id"] for model in config.AVAILABLE_MODELS],
        "model_details": config.AVAILABLE_MODELS
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

if __name__ == "__main__":
    host = os.getenv("HOST", config.HOST)
    port = int(os.getenv("PORT", str(config.PORT)))
    debug = os.getenv("DEBUG", str(config.DEBUG)).lower() == "true"
    
    # Get absolute paths for debugging
    current_dir = Path(__file__).parent
    templates_dir = current_dir / "templates"
    content_dir = current_dir.parent / "content"
    
    print(f"Starting Article Generator Web Server...")
    print(f"Server: http://{host}:{port}")
    print(f"Current directory: {current_dir.absolute()}")
    print(f"Templates directory: {templates_dir.absolute()}")
    print(f"Content directory: {content_dir.absolute()}")
    print(f"Default AI model: {config.DEFAULT_MODEL}")
    
    # Check if required directories exist
    if not templates_dir.exists():
        print(f"ERROR: Templates directory not found: {templates_dir}")
        exit(1)
    
    if not (templates_dir / "index.html").exists():
        print(f"ERROR: index.html template not found in: {templates_dir}")
        exit(1)
    
    # Create content directory if it doesn't exist
    content_dir.mkdir(exist_ok=True)
    print(f"Content directory ready: {content_dir}")
    
    print("All checks passed, starting server...")
    uvicorn.run(app, host=host, port=port, reload=debug)